<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="generator" content="VuePress 2.0.0-beta.29">
    <title>目标检测</title><meta name="description" content="这是一个关于目标检测的故事">
    <link rel="modulepreload" href="/deep-detection/assets/app.797b6d26.js"><link rel="modulepreload" href="/deep-detection/assets/index.html.bbaedabc.js"><link rel="modulepreload" href="/deep-detection/assets/plugin-vue_export-helper.21dcd24c.js"><link rel="modulepreload" href="/deep-detection/assets/index.html.4ab92427.js">
    <link rel="stylesheet" href="/deep-detection/assets/style.f6c364e2.css">
  </head>
  <body>
    <div id="app"><!--[--><div class="theme-container"><!--[--><header ref_key="navbar" class="navbar"><div class="toggle-sidebar-button" title="toggle sidebar" aria-expanded="false" role="button" tabindex="0"><div class="icon" aria-hidden="true"><span></span><span></span><span></span></div></div><span><a href="/deep-detection/" class=""><!----><span class="site-name can-hide">目标检测</span></a></span><div class="navbar-links-wrapper" style=""><!--[--><!--]--><nav class="navbar-links can-hide"><!--[--><div class="navbar-links-item"><a href="/deep-detection/" class="nav-link" aria-label="首页"><!--[--><!--]--> 首页 <!--[--><!--]--></a></div><div class="navbar-links-item"><div class="dropdown-wrapper"><button class="dropdown-title" type="button" aria-label="参考"><span class="title">参考</span><span class="arrow down"></span></button><button class="mobile-dropdown-title" type="button" aria-label="参考"><span class="title">参考</span><span class="right arrow"></span></button><!--[--><ul style="display:none;" class="nav-dropdown"><!--[--><li class="dropdown-item"><!--[--><h4 class="dropdown-subtitle"><span>数据集</span></h4><ul class="dropdown-subitem-wrapper"><!--[--><li class="dropdown-subitem"><a href="/deep-detection/dataset/voc2012/README.md" class="nav-link" aria-label="VOC2012数据"><!--[--><!--]--> VOC2012数据 <!--[--><!--]--></a></li><li class="dropdown-subitem"><a href="/deep-detection/dataset/custom/README.md" class="nav-link" aria-label="自定义数据集制作"><!--[--><!--]--> 自定义数据集制作 <!--[--><!--]--></a></li><!--]--></ul><!--]--></li><li class="dropdown-item"><!--[--><h4 class="dropdown-subtitle"><span>模型</span></h4><ul class="dropdown-subitem-wrapper"><!--[--><li class="dropdown-subitem"><a href="/deep-detection/model/yolov5/README.md" class="nav-link" aria-label="yolov5"><!--[--><!--]--> yolov5 <!--[--><!--]--></a></li><!--]--></ul><!--]--></li><!--]--></ul><!--]--></div></div><!--]--></nav><!--[--><!--]--><button class="toggle-dark-button" title="toggle dark mode"><svg style="" class="icon" focusable="false" viewBox="0 0 32 32"><path d="M16 12.005a4 4 0 1 1-4 4a4.005 4.005 0 0 1 4-4m0-2a6 6 0 1 0 6 6a6 6 0 0 0-6-6z" fill="currentColor"></path><path d="M5.394 6.813l1.414-1.415l3.506 3.506L8.9 10.318z" fill="currentColor"></path><path d="M2 15.005h5v2H2z" fill="currentColor"></path><path d="M5.394 25.197L8.9 21.691l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 25.005h2v5h-2z" fill="currentColor"></path><path d="M21.687 23.106l1.414-1.415l3.506 3.506l-1.414 1.414z" fill="currentColor"></path><path d="M25 15.005h5v2h-5z" fill="currentColor"></path><path d="M21.687 8.904l3.506-3.506l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 2.005h2v5h-2z" fill="currentColor"></path></svg><svg style="display:none;" class="icon" focusable="false" viewBox="0 0 32 32"><path d="M13.502 5.414a15.075 15.075 0 0 0 11.594 18.194a11.113 11.113 0 0 1-7.975 3.39c-.138 0-.278.005-.418 0a11.094 11.094 0 0 1-3.2-21.584M14.98 3a1.002 1.002 0 0 0-.175.016a13.096 13.096 0 0 0 1.825 25.981c.164.006.328 0 .49 0a13.072 13.072 0 0 0 10.703-5.555a1.01 1.01 0 0 0-.783-1.565A13.08 13.08 0 0 1 15.89 4.38A1.015 1.015 0 0 0 14.98 3z" fill="currentColor"></path></svg></button><!----></div></header><!--]--><div class="sidebar-mask"></div><!--[--><aside class="sidebar"><nav class="navbar-links"><!--[--><div class="navbar-links-item"><a href="/deep-detection/" class="nav-link" aria-label="首页"><!--[--><!--]--> 首页 <!--[--><!--]--></a></div><div class="navbar-links-item"><div class="dropdown-wrapper"><button class="dropdown-title" type="button" aria-label="参考"><span class="title">参考</span><span class="arrow down"></span></button><button class="mobile-dropdown-title" type="button" aria-label="参考"><span class="title">参考</span><span class="right arrow"></span></button><!--[--><ul style="display:none;" class="nav-dropdown"><!--[--><li class="dropdown-item"><!--[--><h4 class="dropdown-subtitle"><span>数据集</span></h4><ul class="dropdown-subitem-wrapper"><!--[--><li class="dropdown-subitem"><a href="/deep-detection/dataset/voc2012/README.md" class="nav-link" aria-label="VOC2012数据"><!--[--><!--]--> VOC2012数据 <!--[--><!--]--></a></li><li class="dropdown-subitem"><a href="/deep-detection/dataset/custom/README.md" class="nav-link" aria-label="自定义数据集制作"><!--[--><!--]--> 自定义数据集制作 <!--[--><!--]--></a></li><!--]--></ul><!--]--></li><li class="dropdown-item"><!--[--><h4 class="dropdown-subtitle"><span>模型</span></h4><ul class="dropdown-subitem-wrapper"><!--[--><li class="dropdown-subitem"><a href="/deep-detection/model/yolov5/README.md" class="nav-link" aria-label="yolov5"><!--[--><!--]--> yolov5 <!--[--><!--]--></a></li><!--]--></ul><!--]--></li><!--]--></ul><!--]--></div></div><!--]--></nav><!--[--><!--]--><ul class="sidebar-links"><!--[--><!--[--><p class="sidebar-heading sidebar-item"></p><ul class=""><li><!--[--><a aria-current="page" href="/deep-detection/deploy/yolox/#yolox使用说明" class="router-link-active router-link-exact-active nav-link sidebar-item" aria-label="YOLOX使用说明"><!--[--><!--]--> YOLOX使用说明 <!--[--><!--]--></a><ul class="sidebar-sub-items"><li><!--[--><a aria-current="page" href="/deep-detection/deploy/yolox/#什么是yolox" class="router-link-active router-link-exact-active nav-link sidebar-item" aria-label="什么是YOLOX？"><!--[--><!--]--> 什么是YOLOX？ <!--[--><!--]--></a><!----><!--]--></li><li><!--[--><a aria-current="page" href="/deep-detection/deploy/yolox/#快速使用" class="router-link-active router-link-exact-active nav-link sidebar-item" aria-label="快速使用"><!--[--><!--]--> 快速使用 <!--[--><!--]--></a><!----><!--]--></li><li><!--[--><a aria-current="page" href="/deep-detection/deploy/yolox/#数据集训练-coco" class="router-link-active router-link-exact-active nav-link sidebar-item" aria-label="数据集训练（COCO）"><!--[--><!--]--> 数据集训练（COCO） <!--[--><!--]--></a><!----><!--]--></li><li><!--[--><a aria-current="page" href="/deep-detection/deploy/yolox/#训练权重转换" class="router-link-active router-link-exact-active nav-link sidebar-item" aria-label="训练权重转换"><!--[--><!--]--> 训练权重转换 <!--[--><!--]--></a><!----><!--]--></li><li><!--[--><a aria-current="page" href="/deep-detection/deploy/yolox/#验证模型" class="router-link-active router-link-exact-active nav-link sidebar-item" aria-label="验证模型"><!--[--><!--]--> 验证模型 <!--[--><!--]--></a><!----><!--]--></li></ul><!--]--></li></ul><!--]--><!--]--></ul><!--[--><!--]--></aside><!--]--><!--[--><main class="page"><!--[--><!--]--><div class="theme-default-content"><!--[--><h2 id="yolox使用说明" tabindex="-1"><a class="header-anchor" href="#yolox使用说明" aria-hidden="true">#</a> YOLOX使用说明</h2><h3 id="什么是yolox" tabindex="-1"><a class="header-anchor" href="#什么是yolox" aria-hidden="true">#</a> 什么是<a href="https://github.com/Megvii-BaseDetection/YOLOX" target="_blank" rel="noopener noreferrer">YOLOX<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><!--[--><span class="sr-only">open in new window</span><!--]--></span></a>？</h3><p><img src="/deep-detection/assets/logo.3812954e.png" alt="rect"></p><p>​ YOLOX是旷视科技基于YOLO系列改进而成的高性能目标检测器，结合了近两年出现的anchor-free，标签分配，数据增广等技术，向较于YOLOv3, YOLOv4, YOLOv5等拥有更高的性能，可以有效地弥合目标检测领域内技术研究与产业应用之间的差距</p><h3 id="快速使用" tabindex="-1"><a class="header-anchor" href="#快速使用" aria-hidden="true">#</a> 快速使用</h3><p><strong>1.安装YOLOX</strong></p><div class="language-text ext-text line-numbers-mode"><pre class="language-text"><code>git clone git@github.com:Megvii-BaseDetection/YOLOX.git
cd YOLOX
pip3 install -U pip &amp;&amp; pip3 install -r requirements.txt
pip3 install -v -e .  # or  python3 setup.py develop
</code></pre><div class="line-numbers"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p><strong>2.安装<a href="https://github.com/cocodataset/cocoapi" target="_blank" rel="noopener noreferrer">pycocotools<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><!--[--><span class="sr-only">open in new window</span><!--]--></span></a></strong></p><div class="language-text ext-text line-numbers-mode"><pre class="language-text"><code>pip3 install cython; pip3 install &#39;git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI&#39;
</code></pre><div class="line-numbers"><span class="line-number">1</span><br></div></div><p><strong>3.验证安装环境</strong></p><p>下载官方提供的训练好的权重模型yolox_s.pth，运行以下指令</p><div class="language-text ext-text line-numbers-mode"><pre class="language-text"><code>cd YOLOX
python tools/demo.py image -n yolox-s -c /path/to/your/yolox_s.pth --path assets/dog.jpg --conf 0.25 --nms 0.45 --tsize 640 --save_result --device [cpu/gpu]
</code></pre><div class="line-numbers"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><div class="language-text ext-text line-numbers-mode"><pre class="language-text"><code>python tools/demo.py image -f exps/example/custom/yolox_s.py -c yolox_s.pth --path assets/dog.jpg --conf 0.25 --nms 0.45 --tsize 640 --save_result --device [cpu/gpu]
</code></pre><div class="line-numbers"><span class="line-number">1</span><br></div></div><p>所保存图像如下所示则说明环境配置成功</p><p><img src="/deep-detection/assets/dog.82758e07.jpg" alt="rect"></p><h3 id="数据集训练-coco" tabindex="-1"><a class="header-anchor" href="#数据集训练-coco" aria-hidden="true">#</a> 数据集训练（COCO）</h3><p>YOLOX的数据集训练有COCO和VOC两种方式，以下将简要概述使用COCO数据集训练的方法：</p><p><strong>1.标注</strong>：使用<a href="https://github.com/tzutalin/labelImg" target="_blank" rel="noopener noreferrer">labelImg<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><!--[--><span class="sr-only">open in new window</span><!--]--></span></a> 对数据集进行标注</p><p><strong>2.数据集结构转换</strong>：参考<a href="https://github.com/RapidAI/YOLO2COCO" target="_blank" rel="noopener noreferrer">YOLO2COCO<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><!--[--><span class="sr-only">open in new window</span><!--]--></span></a>等项目将数据集结构转换为如下格式：</p><div class="language-text ext-text line-numbers-mode"><pre class="language-text"><code>VOC
├── annotations
├── train2017
    ├── 0000001.jpg
    ├── ...
├── val2017
    ├── 0000001.jpg
    ├── ...
</code></pre><div class="line-numbers"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><p><strong>3.数据集转移</strong>：将数据集<code>VOC</code>转移至<code>$YOLOX_DIR/datasets</code></p><p><strong>4.修改数据集保存路径与类别个数</strong>：在文件路径<code>YOLOX_DIR/exps/example/custom/yolox_s.py</code>中，将<code>self.data_dir</code>修改为自己数据集的保存路径，将<code>self.num_classes</code>修改为自己数据集所要识别的类别个数</p><p><img src="/deep-detection/assets/image-1.d5ba703f.png" alt="rect"></p><p><strong>5.修改数据集名称</strong>：在文件路径<code> YOLOX_DIR/yolox/data/datasets/coco_classes.py</code>处将<code>COCO_CLASSES</code>修改为自己数据集所要识别的类别名称</p><p><img src="/deep-detection/assets/image-2.92f459d2.png" alt="rect"></p><p><strong>6.训练数据集</strong></p><p>在<code>/YOLOX_DIR</code>下执行以下命令：</p><div class="language-text ext-text line-numbers-mode"><pre class="language-text"><code>python3 tools/train.py -f exps/example/custom/yolox_s.py -d 1 -b 64 --fp16  -c yolox_s.pth
</code></pre><div class="line-numbers"><span class="line-number">1</span><br></div></div><p>训练所得结果保存在<code>YOLOX_DIR/YOLOX_outputs/yolox_s</code>中</p><h3 id="训练权重转换" tabindex="-1"><a class="header-anchor" href="#训练权重转换" aria-hidden="true">#</a> 训练权重转换</h3><p>模型训练完成后需要将<code>.pth</code>文件转换为OpenVINO所需要的<code>.xml</code>与<code>.bin</code>文件，转化流程如下所示：</p><div class="language-text ext-text line-numbers-mode"><pre class="language-text"><code>  .pth-&gt; .onnx  # 通过执行文件 /tools/export_onnx.py
            └─&gt; .onnx -&gt; .xml/.bin  #通过执行文件：/opt/intel/openvino_DIR/deployment_tools/model_optimizer/mo_onnx.py
</code></pre><div class="line-numbers"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p><strong>1.pth2onnx</strong></p><div class="language-text ext-text line-numbers-mode"><pre class="language-text"><code>python3 tools/export_onnx.py --output-name best01.onnx -f exps/example/custom/yolox_s.py -c best01.pth
</code></pre><div class="line-numbers"><span class="line-number">1</span><br></div></div><p><strong>2.onnx2xml</strong></p><div class="language-text ext-text line-numbers-mode"><pre class="language-text"><code>python3 /opt/intel/openvino_2021/deployment_tools/model_optimizer/mo_onnx.py --input_model best01.onnx --input_shape [1,3,640,640] --data_type FP16 --output_dir converted_output
</code></pre><div class="line-numbers"><span class="line-number">1</span><br></div></div><h3 id="验证模型" tabindex="-1"><a class="header-anchor" href="#验证模型" aria-hidden="true">#</a> 验证模型</h3><p><code>YOLOX_DIR/demo/OpenVINO</code>中有c++和python两套使用OpenVINO部署YOLOX的代码，执行相应指令验证训练结果(以python为例)</p><div class="language-text ext-text line-numbers-mode"><pre class="language-text"><code>cd ~/YOLOX/demo/OpenVINO/python
python3 openvino_inference.py -m best00.xml -i cola.jpg
</code></pre><div class="line-numbers"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><!--]--></div><footer class="page-meta"><!----><div class="meta-item last-updated"><span class="meta-item-label">Last Updated: </span><!----></div><div class="meta-item contributors"><span class="meta-item-label">Contributors: </span><span class="meta-item-info"><!--[--><!--[--><span class="contributor" title="email: 91844263+linklllllllll@users.noreply.github.com">linklllllllll</span><!--[-->, <!--]--><!--]--><!--[--><span class="contributor" title="email: 38650110+HenryZhuHR@users.noreply.github.com">Henry Zhu</span><!----><!--]--><!--]--></span></div></footer><!----><!--[--><!--]--></main><!--]--></div><!----><!--]--></div>
    <script type="module" src="/deep-detection/assets/app.797b6d26.js" defer></script>
  </body>
</html>
