<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="generator" content="VuePress 2.0.0-beta.29">
    <title>目标检测</title><meta name="description" content="这是一个关于目标检测的故事">
    <link rel="modulepreload" href="/deep-detection/assets/app.797b6d26.js"><link rel="modulepreload" href="/deep-detection/assets/index.html.7c2c9aec.js"><link rel="modulepreload" href="/deep-detection/assets/plugin-vue_export-helper.21dcd24c.js"><link rel="modulepreload" href="/deep-detection/assets/index.html.c4f0ca4b.js">
    <link rel="stylesheet" href="/deep-detection/assets/style.f6c364e2.css">
  </head>
  <body>
    <div id="app"><!--[--><div class="theme-container"><!--[--><header ref_key="navbar" class="navbar"><div class="toggle-sidebar-button" title="toggle sidebar" aria-expanded="false" role="button" tabindex="0"><div class="icon" aria-hidden="true"><span></span><span></span><span></span></div></div><span><a href="/deep-detection/" class=""><!----><span class="site-name can-hide">目标检测</span></a></span><div class="navbar-links-wrapper" style=""><!--[--><!--]--><nav class="navbar-links can-hide"><!--[--><div class="navbar-links-item"><a href="/deep-detection/" class="nav-link" aria-label="首页"><!--[--><!--]--> 首页 <!--[--><!--]--></a></div><div class="navbar-links-item"><div class="dropdown-wrapper"><button class="dropdown-title" type="button" aria-label="参考"><span class="title">参考</span><span class="arrow down"></span></button><button class="mobile-dropdown-title" type="button" aria-label="参考"><span class="title">参考</span><span class="right arrow"></span></button><!--[--><ul style="display:none;" class="nav-dropdown"><!--[--><li class="dropdown-item"><!--[--><h4 class="dropdown-subtitle"><span>数据集</span></h4><ul class="dropdown-subitem-wrapper"><!--[--><li class="dropdown-subitem"><a href="/deep-detection/dataset/voc2012/README.md" class="nav-link" aria-label="VOC2012数据"><!--[--><!--]--> VOC2012数据 <!--[--><!--]--></a></li><li class="dropdown-subitem"><a href="/deep-detection/dataset/custom/README.md" class="nav-link" aria-label="自定义数据集制作"><!--[--><!--]--> 自定义数据集制作 <!--[--><!--]--></a></li><!--]--></ul><!--]--></li><li class="dropdown-item"><!--[--><h4 class="dropdown-subtitle"><span>模型</span></h4><ul class="dropdown-subitem-wrapper"><!--[--><li class="dropdown-subitem"><a href="/deep-detection/model/yolov5/README.md" class="nav-link" aria-label="yolov5"><!--[--><!--]--> yolov5 <!--[--><!--]--></a></li><!--]--></ul><!--]--></li><!--]--></ul><!--]--></div></div><!--]--></nav><!--[--><!--]--><button class="toggle-dark-button" title="toggle dark mode"><svg style="" class="icon" focusable="false" viewBox="0 0 32 32"><path d="M16 12.005a4 4 0 1 1-4 4a4.005 4.005 0 0 1 4-4m0-2a6 6 0 1 0 6 6a6 6 0 0 0-6-6z" fill="currentColor"></path><path d="M5.394 6.813l1.414-1.415l3.506 3.506L8.9 10.318z" fill="currentColor"></path><path d="M2 15.005h5v2H2z" fill="currentColor"></path><path d="M5.394 25.197L8.9 21.691l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 25.005h2v5h-2z" fill="currentColor"></path><path d="M21.687 23.106l1.414-1.415l3.506 3.506l-1.414 1.414z" fill="currentColor"></path><path d="M25 15.005h5v2h-5z" fill="currentColor"></path><path d="M21.687 8.904l3.506-3.506l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 2.005h2v5h-2z" fill="currentColor"></path></svg><svg style="display:none;" class="icon" focusable="false" viewBox="0 0 32 32"><path d="M13.502 5.414a15.075 15.075 0 0 0 11.594 18.194a11.113 11.113 0 0 1-7.975 3.39c-.138 0-.278.005-.418 0a11.094 11.094 0 0 1-3.2-21.584M14.98 3a1.002 1.002 0 0 0-.175.016a13.096 13.096 0 0 0 1.825 25.981c.164.006.328 0 .49 0a13.072 13.072 0 0 0 10.703-5.555a1.01 1.01 0 0 0-.783-1.565A13.08 13.08 0 0 1 15.89 4.38A1.015 1.015 0 0 0 14.98 3z" fill="currentColor"></path></svg></button><!----></div></header><!--]--><div class="sidebar-mask"></div><!--[--><aside class="sidebar"><nav class="navbar-links"><!--[--><div class="navbar-links-item"><a href="/deep-detection/" class="nav-link" aria-label="首页"><!--[--><!--]--> 首页 <!--[--><!--]--></a></div><div class="navbar-links-item"><div class="dropdown-wrapper"><button class="dropdown-title" type="button" aria-label="参考"><span class="title">参考</span><span class="arrow down"></span></button><button class="mobile-dropdown-title" type="button" aria-label="参考"><span class="title">参考</span><span class="right arrow"></span></button><!--[--><ul style="display:none;" class="nav-dropdown"><!--[--><li class="dropdown-item"><!--[--><h4 class="dropdown-subtitle"><span>数据集</span></h4><ul class="dropdown-subitem-wrapper"><!--[--><li class="dropdown-subitem"><a href="/deep-detection/dataset/voc2012/README.md" class="nav-link" aria-label="VOC2012数据"><!--[--><!--]--> VOC2012数据 <!--[--><!--]--></a></li><li class="dropdown-subitem"><a href="/deep-detection/dataset/custom/README.md" class="nav-link" aria-label="自定义数据集制作"><!--[--><!--]--> 自定义数据集制作 <!--[--><!--]--></a></li><!--]--></ul><!--]--></li><li class="dropdown-item"><!--[--><h4 class="dropdown-subtitle"><span>模型</span></h4><ul class="dropdown-subitem-wrapper"><!--[--><li class="dropdown-subitem"><a href="/deep-detection/model/yolov5/README.md" class="nav-link" aria-label="yolov5"><!--[--><!--]--> yolov5 <!--[--><!--]--></a></li><!--]--></ul><!--]--></li><!--]--></ul><!--]--></div></div><!--]--></nav><!--[--><!--]--><ul class="sidebar-links"><!--[--><!--[--><p class="sidebar-heading sidebar-item"></p><ul class=""><li><!--[--><a aria-current="page" href="/deep-detection/deploy/yolov5-lite/#yolov5-lite使用说明" class="router-link-active router-link-exact-active nav-link sidebar-item" aria-label="YOLOv5-Lite使用说明"><!--[--><!--]--> YOLOv5-Lite使用说明 <!--[--><!--]--></a><ul class="sidebar-sub-items"><li><!--[--><a aria-current="page" href="/deep-detection/deploy/yolov5-lite/#什么是yolov5-lite" class="router-link-active router-link-exact-active nav-link sidebar-item" aria-label="什么是YOLOv5-Lite？"><!--[--><!--]--> 什么是YOLOv5-Lite？ <!--[--><!--]--></a><!----><!--]--></li><li><!--[--><a aria-current="page" href="/deep-detection/deploy/yolov5-lite/#快速使用" class="router-link-active router-link-exact-active nav-link sidebar-item" aria-label="快速使用"><!--[--><!--]--> 快速使用 <!--[--><!--]--></a><!----><!--]--></li><li><!--[--><a aria-current="page" href="/deep-detection/deploy/yolov5-lite/#数据集训练" class="router-link-active router-link-exact-active nav-link sidebar-item" aria-label="数据集训练"><!--[--><!--]--> 数据集训练 <!--[--><!--]--></a><!----><!--]--></li><li><!--[--><a aria-current="page" href="/deep-detection/deploy/yolov5-lite/#训练权重转换" class="router-link-active router-link-exact-active nav-link sidebar-item" aria-label="训练权重转换"><!--[--><!--]--> 训练权重转换 <!--[--><!--]--></a><!----><!--]--></li><li><!--[--><a aria-current="page" href="/deep-detection/deploy/yolov5-lite/#验证模型" class="router-link-active router-link-exact-active nav-link sidebar-item" aria-label="验证模型"><!--[--><!--]--> 验证模型 <!--[--><!--]--></a><!----><!--]--></li></ul><!--]--></li></ul><!--]--><!--]--></ul><!--[--><!--]--></aside><!--]--><!--[--><main class="page"><!--[--><!--]--><div class="theme-default-content"><!--[--><h2 id="yolov5-lite使用说明" tabindex="-1"><a class="header-anchor" href="#yolov5-lite使用说明" aria-hidden="true">#</a> YOLOv5-Lite使用说明</h2><h3 id="什么是yolov5-lite" tabindex="-1"><a class="header-anchor" href="#什么是yolov5-lite" aria-hidden="true">#</a> 什么是<a href="https://github.com/ppogg/YOLOv5-Lite" target="_blank" rel="noopener noreferrer">YOLOv5-Lite<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><!--[--><span class="sr-only">open in new window</span><!--]--></span></a>？</h3><p>YOLOv5-Lite是在YOLOv5的基础上进行一系列消融实验得到的更轻(Flops更小，内存更低，参数更少)，速度更快(增加shuffle channel, yolov5 head for channel reduce)的目标检测模型。当使用320×320输入帧时，在Raspberry Pi 4B上可以推断出至少10+ FPS)，并且更容易部署(删除Focus层和4个切片操作，将模型量化精度降低到一个可接受的范围)。</p><h3 id="快速使用" tabindex="-1"><a class="header-anchor" href="#快速使用" aria-hidden="true">#</a> 快速使用</h3><p><strong>1.安装YOLOv5-Lite</strong></p><div class="language-text ext-text line-numbers-mode"><pre class="language-text"><code>$ git clone https://github.com/ppogg/YOLOv5-Lite
$ cd YOLOv5-Lite
$ pip install -r requirements.txt
</code></pre><div class="line-numbers"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p><strong>2.验证安装环境</strong></p><p>在<a href="https://github.com/ppogg/YOLOv5-Lite/releases" target="_blank" rel="noopener noreferrer">latest YOLOv5-Lite release<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><!--[--><span class="sr-only">open in new window</span><!--]--></span></a> 中下载对应权重文件，运行以下指令调用demo文件,文件将自动保存在 <code>runs/detect</code>中</p><div class="language-text ext-text line-numbers-mode"><pre class="language-text"><code>$ python detect.py --source 0  # webcam
                            file.jpg  # image 
                            file.mp4  # video
                            path/  # directory
                            path/*.jpg  # glob
                            &#39;https://youtu.be/NUsoVlDFqZg&#39;  # YouTube
                            &#39;rtsp://example.com/media.mp4&#39;  # RTSP, RTMP, HTTP stream
</code></pre><div class="line-numbers"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><h3 id="数据集训练" tabindex="-1"><a class="header-anchor" href="#数据集训练" aria-hidden="true">#</a> 数据集训练</h3><p><strong>1.标注</strong>:使用<a href="https://github.com/tzutalin/labelImg" target="_blank" rel="noopener noreferrer">labelImg<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><!--[--><span class="sr-only">open in new window</span><!--]--></span></a> 对数据集进行标注</p><p><strong>2.数据集结构转换</strong>:数据集结构与YOLOv5一致，结构如下所示：</p><div class="language-text ext-text line-numbers-mode"><pre class="language-text"><code>└── dataset-custom  # 数据集文件夹
    ├── src         # 原始数据，按照类别进行归档
    ├── labeled     # 压缩、重命名后的文件，在这里进行标注
    └── coco        # coco 数据集，用于训练
        ├── images
        │   ├── train2017
        │   └── val2017
        └── labels   
            ├── train2017
            └── val2017
</code></pre><div class="line-numbers"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br></div></div><p><strong>3.修改数据集类别个数与名称与保存路径</strong>:在文件路径<code>YOLOv5-Lite_DIR/data/cocol.yaml</code>中，将<code>names</code>修改为自己数据集所要识别的名称，将<code>nc</code>修改为自己数据集所要识别的类别个数,将<code>train</code>,<code>val</code>,<code>test</code>修改为数据集对应位置</p><p><img src="/deep-detection/assets/image-1.ece1fbec.png" alt="image-20220311185943426"></p><p><strong>4.训练数据集</strong></p><p>在<code>/YOLOv5-Lite</code>下执行以下命令：</p><div class="language-text ext-text line-numbers-mode"><pre class="language-text"><code>$ python train.py --data coco.yaml --cfg v5lite-s.yaml --weights v5lite-s.pt --batch-size 128
                                         v5lite-c.yaml           v5lite-c.pt               96
                                         v5lite-g.yaml           v5lite-g.pt               64
</code></pre><div class="line-numbers"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>训练所得结果保存在<code>YOLOv5-Lite/runs/train/exp</code>中</p><h3 id="训练权重转换" tabindex="-1"><a class="header-anchor" href="#训练权重转换" aria-hidden="true">#</a> 训练权重转换</h3><p>模型训练完成后需要将<code>.pt</code>文件转换为OpenVINO所需要的<code>.xml</code>与<code>.bin</code>文件，转化流程如下所示：</p><div class="language-text ext-text line-numbers-mode"><pre class="language-text"><code>  .pt-&gt; .onnx  # 通过执行文件 /models/export.py
            └─&gt; .onnx -&gt; .xml/.bin  #通过执行文件：/opt/intel/openvino_DIR/deployment_tools/model_optimizer/mo_onnx.py
</code></pre><div class="line-numbers"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p><strong>1.pth2onnx</strong></p><div class="language-text ext-text line-numbers-mode"><pre class="language-text"><code>python3 models/export.py --weights weights/v5lite-c.pt --img 640 --batch 1
</code></pre><div class="line-numbers"><span class="line-number">1</span><br></div></div><p><strong>2.onnx2xml</strong></p><div class="language-text ext-text line-numbers-mode"><pre class="language-text"><code>python3 /opt/intel/openvino_2021/deployment_tools/model_optimizer/mo_onnx.py --input_model best.onnx -s 255 --data_type FP16  --reverse_input_channels --output Conv_454,Conv_457,Conv_460  ##输出应通过netorn等软件选取
</code></pre><div class="line-numbers"><span class="line-number">1</span><br></div></div><h3 id="验证模型" tabindex="-1"><a class="header-anchor" href="#验证模型" aria-hidden="true">#</a> 验证模型</h3><p><code>YOLOv5-Lite/demo/OpenVINO</code>中有c++和python两套使用OpenVINO部署YOLOX的代码，执行相应指令验证训练结果(以python为例)</p><div class="language-text ext-text line-numbers-mode"><pre class="language-text"><code>cd ~/YOLOv5-Lite/python_demo/openvino
python3 openvino.py -m best.xml -i bike.jpg
</code></pre><div class="line-numbers"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><!--]--></div><footer class="page-meta"><!----><div class="meta-item last-updated"><span class="meta-item-label">Last Updated: </span><!----></div><div class="meta-item contributors"><span class="meta-item-label">Contributors: </span><span class="meta-item-info"><!--[--><!--[--><span class="contributor" title="email: 91844263+linklllllllll@users.noreply.github.com">linklllllllll</span><!----><!--]--><!--]--></span></div></footer><!----><!--[--><!--]--></main><!--]--></div><!----><!--]--></div>
    <script type="module" src="/deep-detection/assets/app.797b6d26.js" defer></script>
  </body>
</html>
